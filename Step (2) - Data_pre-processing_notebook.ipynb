{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:44:34.235905Z",
     "start_time": "2022-03-13T05:44:25.792643Z"
    }
   },
   "outputs": [],
   "source": [
    "import arabic_reshaper                   # pip install arabic-reshaper\n",
    "from bidi.algorithm import get_display   # pip install python-bidi\n",
    "from emoji import get_emoji_regexp       # pip install emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:44:34.264885Z",
     "start_time": "2022-03-13T05:44:34.238900Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_stopwords(file_path = './data/arabic_stopwords_list_nw.txt'):\n",
    "    with open(file_path, 'r', encoding = 'utf-8') as stopwords_file:\n",
    "        stopwords = [word.strip() for word in stopwords_file.readlines()]\n",
    "    # End file stream\n",
    "    return stopwords\n",
    "# End Func\n",
    "\n",
    "def format_arabic(text):\n",
    "    text = arabic_reshaper.reshape(text)\n",
    "    text = get_display(text)\n",
    "    return text\n",
    "# End Func\n",
    "\n",
    "def preprocess_text(text, remove_stopwords = False, stem = False, return_tokens = False):\n",
    "    # Remove mentions, hashtags or any english words and numbers \n",
    "    cleaning_regex_script = re.compile(pattern=r'(\\@\\w+|\\#\\w+|[A-Za-z0-9]+)')\n",
    "    text = cleaning_regex_script.sub('', text)\n",
    "\n",
    "    # Remove emojies\n",
    "    emoji_regex = get_emoji_regexp()\n",
    "    text = emoji_regex.sub('', text)\n",
    "\n",
    "    # Remove punctuations and some symbols\n",
    "    arabic_punctuations = '''`÷×٪؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ.'''\n",
    "    symbols = '❤♡❀♩﴾﴿↓❁♬'\n",
    "    puncts = arabic_punctuations + string.punctuation + symbols\n",
    "    text = text.translate(str.maketrans('', '', puncts))    \n",
    "\n",
    "    # Remove Arabic Digits\n",
    "    arabic_numbers_digits = r'[٠١٢٣٤٥٦٧٨٩]+'\n",
    "    text = re.sub(arabic_numbers_digits, '', text)\n",
    "\n",
    "    # Remove unnessary spaces\n",
    "    spaces_regex_script = re.compile(pattern=r'[\\s]{2,}')\n",
    "    text = spaces_regex_script.sub(' ', text).strip()\n",
    "\n",
    "    # Remove arabic diacritics\n",
    "    arabic_diacritics = r'[ًٌٍَُِّـ]'\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "\n",
    "    # Normalize the arabic text alpha\n",
    "    text = re.sub(\"[إأآ]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "\n",
    "    # Tokenize text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    if remove_stopwords:\n",
    "        stopwords = load_stopwords()\n",
    "        tokens = [token for token in tokens if token not in stopwords and token.isalpha()]\n",
    "    # End if\n",
    "    \n",
    "    # Get words root using stemming\n",
    "    if stem:\n",
    "        stemmer = ISRIStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    # End if\n",
    "    \n",
    "    preprocessed_text = tokens if return_tokens else ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "# End Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:44:34.294919Z",
     "start_time": "2022-03-13T05:44:34.269882Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = './data/dialects_data_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:44:39.194139Z",
     "start_time": "2022-03-13T05:44:34.297913Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path).drop(columns = ['id']).replace([''], np.nan).dropna().reset_index(drop = True)\n",
    "df['dialect'] = pd.Categorical(df['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:56:04.409405Z",
     "start_time": "2022-03-13T05:44:39.197139Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(preprocess_text).astype('U').copy()\n",
    "df['label'] = df['dialect'].values.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:56:04.450376Z",
     "start_time": "2022-03-13T05:56:04.412403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .</td>\n",
       "      <td>IQ</td>\n",
       "      <td>لكن بالنهايه ينتفض يغير</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يعني هذا محسوب علي البشر حيونه ووحشيه وتطلبون ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KanaanRema مبين من كلامه خليجي</td>\n",
       "      <td>IQ</td>\n",
       "      <td>مبين من كلامه خليجي</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@HAIDER76128900 يسلملي مرورك وروحك الحلوه💐</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@hmo2406 وين هل الغيبه  اخ محمد 🌸🌺</td>\n",
       "      <td>IQ</td>\n",
       "      <td>وين هل الغيبه اخ محمد</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text dialect  \\\n",
       "0   @Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .      IQ   \n",
       "1  @7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...      IQ   \n",
       "2                    @KanaanRema مبين من كلامه خليجي      IQ   \n",
       "3         @HAIDER76128900 يسلملي مرورك وروحك الحلوه💐      IQ   \n",
       "4                 @hmo2406 وين هل الغيبه  اخ محمد 🌸🌺      IQ   \n",
       "\n",
       "                                        cleaned_text  label  \n",
       "0                            لكن بالنهايه ينتفض يغير      4  \n",
       "1  يعني هذا محسوب علي البشر حيونه ووحشيه وتطلبون ...      4  \n",
       "2                                مبين من كلامه خليجي      4  \n",
       "3                          يسلملي مرورك وروحك الحلوه      4  \n",
       "4                              وين هل الغيبه اخ محمد      4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:56:05.124971Z",
     "start_time": "2022-03-13T05:56:04.456375Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, valid_test_df = train_test_split(df[['cleaned_text', 'label']], test_size = 0.2, stratify = df['label'])\n",
    "valid_df, test_df = train_test_split(valid_test_df, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:56:11.069643Z",
     "start_time": "2022-03-13T05:56:05.130968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Preprocessed Version\n",
    "df[['cleaned_text', 'dialect']].to_csv('./data/dataset_cleaned_version.csv', index = False)\n",
    "train_df.to_csv('./data/dataset_cleaned_version_train.csv', index = False)\n",
    "valid_df.to_csv('./data/dataset_cleaned_version_valid.csv', index = False)\n",
    "test_df.to_csv('./data/dataset_cleaned_version_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
